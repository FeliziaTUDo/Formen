{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Formerkennung_mit_Neuronalem_Netz.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R3SHZrb-r3up",
        "7Kk1RB6UkkLi",
        "julQYl0tkx9I",
        "H2Oa8j35k2cG",
        "xW3gD0Y3unw-",
        "JidTa0BkIQOj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnJIPCG-99_1"
      },
      "source": [
        "---\n",
        "# Ziel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBdV8RJz-Om6"
      },
      "source": [
        "In diesem Notebook wird der Ablauf zum Erstellen und Trainieren eines Neuronalen Netzes mit Keras gezeigt. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5NQdqjE-RSX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SHZrb-r3up"
      },
      "source": [
        "# 1. Allgemeine Vorbereitung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeW-Hl5E8vFA"
      },
      "source": [
        "Navigiere in den Ordner \"KI\" \r\n",
        "\r\n",
        "(Dieser wurde in der vorangegangenen Klickanleitung erstellt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ip554ajtuxA",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6d7420-e8d1-464d-9bb2-92c2fcefdbae"
      },
      "source": [
        "%cd ~/../content/drive/My\\ Drive/KI/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/KI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Vscsdxswxc"
      },
      "source": [
        "In Google Colab sind viele Bibliotheken bereits vorinstalliert und können mit einem einfachen import-Befehl in das aktuelle Notebook importiert werden. \n",
        "Zum Ausführen dieses Notebooks werden die drei Bibliotheken keras, matplotlib und numpy benötigt, die folgende Funktionen erfüllen:\n",
        "\n",
        "\n",
        "* keras: Funktionen für das Neuronale Netz\n",
        "\n",
        "* matplotlib: Zum Anzeigen von Bildern und Plotten von Funktionen\n",
        "\n",
        "* numpy: Zur numerischen Berechnung von Arrays\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awnac25OGU_Y",
        "cellView": "both"
      },
      "source": [
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXp5sKLlGAq_"
      },
      "source": [
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Kk1RB6UkkLi"
      },
      "source": [
        "# 2. Erstellen des Datensets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbbtmDIyGoNB"
      },
      "source": [
        "In Github befindet sich ein Datenset mit Bildern von Kreisen, Dreiecken und Vierecken. Dieses Datenset wird mit folgendem Befehl heruntergeladen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPgwkKNCebCJ",
        "outputId": "f3105813-d51c-4225-a774-647fc2beb748"
      },
      "source": [
        "!git clone https://github.com/FeliziaTUDo/Formen.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Formen' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ3tNqNpG5BT"
      },
      "source": [
        "Aufgabe 1\r\n",
        "\r\n",
        "(Die Lösung zu allen Aufgaben befindet sich am Ende dieses Notebooks unter der Überschrift \"Lösungen zu den Aufgaben\")\r\n",
        "\r\n",
        "1a.) Öffne die Ordnerstruktur am linken Rand des Notebooks. In welchem Verzeichnis wurden die Bilder gespeichert? \r\n",
        "\r\n",
        "1b.) Nach welchem System wurden die Bilder sortiert? Weshalb ist diese Sortierung notwendig? \r\n",
        "\r\n",
        "1c.) Um die Trainingsbilder und Testbildern in ein Datenset einzufügen, wird der Pfad dorthin ebnötigt. In der nächsten Zelle wird der Pfad für die Trainignsbilder mit der Variable path_train_images angegeben. Gib nach dem gleichen Schema den den Pfad für die Testbilder unter der Variable path_test_images an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYxSO4I_UxOc"
      },
      "source": [
        "path_train_images = './Formen/train'\r\n",
        "path_test_images = ''"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHo9KJkrHcWg"
      },
      "source": [
        "Im nächsten Schritt werden die Bilder in einem Datenset angeordnet. Zu jedem Bild wird die entsprechende Klasse (= Label) gespeichert. \r\n",
        "\r\n",
        "In unserem Datenset sind alle Bilder bereits in der gleichen Größe. In anderen Datensets kann es der Fall sein, dass Bilder unterschiedlich groß sind. Diese Bilder werden bei Anordnung im Datenset auf die vorgegebene Größe verkleinert. \r\n",
        "\r\n",
        "Daher wird zu Begin die Seitenlänge des Bildes in Pixeln in der Variablen image_side_lentgh festgelegt. In diesem Fall beträgt die Seitenlänge des Bildes 28 Pixel. \r\n",
        "\r\n",
        "Aufgabe 2: Warum müssen alle Bilder die gleiche Seitenlänge haben?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qikANhfNf_Js"
      },
      "source": [
        "# Welche Seitenlänge in Pixeln sollen die Bilder haben?\n",
        "image_side_lentgh = 28"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBzvz_aROeRF"
      },
      "source": [
        "In der nächsten Zelle werden die Bilder in ein Datenset zusammengefügt. \r\n",
        "\r\n",
        "Mit der Keras-Funktion ImageDataGenerator werden einzelne Packete (\"Batches\") aus Bilddaten erzeugt. \r\n",
        "\r\n",
        "Mit rescale wird ein Faktor angegeben, mit dem alle eingehenden Daten multipliziert werden. Die Helligkeitswerte befinden sich in Werten von 0 (schwarz) bis 255 (weiß). Um diese auf Werte zwischen 0 und 1 zu normieren, wird der unten gezeigte rescale-Faktor angewendet.\r\n",
        "\r\n",
        "Der validation_split gibt an, wie groß der Anteil der Bilder ist, die nicht für den Lernprozess verwendet werden, sondern mit denen die Qualität der Gewichte des Netzes überprüft wird.  \r\n",
        "\r\n",
        "Weitere Informationen zum ImageDataGenerator befinden sich hier: https://keras.io/api/preprocessing/image/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yO5yqMkR94l"
      },
      "source": [
        "# Einstellung zum Einlesen der Bilder\n",
        "data_generation = ImageDataGenerator(rescale = 1./ 255,\n",
        "                                     validation_split=0.25)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On6EGwkjUiTe"
      },
      "source": [
        "Ein Trainingsdatenset und ein Validationsdatenset werden erstellt. \r\n",
        "\r\n",
        "Hier wird der Pfad zu den Trainingsbildern und die Seitenlänge der Bilder angegeben. Über die Variable batch_size wird die Anzahl der Bilder festgelegt, nach der die Gewichte des Neuronalen Netzes aktualisiert werden. Mit class_mode wird die Art des Abspeicherns der Labels festgelegt.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfk0_lNNUepy",
        "outputId": "f80a7bc1-b005-4b53-8d66-066a5dec861e"
      },
      "source": [
        "## Trainingsdatenset\r\n",
        "train_images = data_generation.flow_from_directory( path_train_images,\r\n",
        "                                                    target_size = (image_side_lentgh,image_side_lentgh),\r\n",
        "                                                    batch_size = 32,\r\n",
        "                                                    seed = 100,\r\n",
        "                                                    class_mode = 'categorical',\r\n",
        "                                                    color_mode = 'grayscale',\r\n",
        "                                                    subset='training'\r\n",
        "                                                    )\r\n",
        "\r\n",
        "## Validationdatenset\r\n",
        "validation_images = data_generation.flow_from_directory(path_train_images,\r\n",
        "                                                    target_size=(image_side_lentgh,image_side_lentgh),\r\n",
        "                                                    batch_size = 32,\r\n",
        "                                                    seed = 100,\r\n",
        "                                                    class_mode='categorical',\r\n",
        "                                                    color_mode = 'grayscale',\r\n",
        "                                                    subset='validation')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1261 images belonging to 3 classes.\n",
            "Found 419 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK7RC76MGG2m"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "julQYl0tkx9I"
      },
      "source": [
        "# 3. Aufbau des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl1YAVFEXrxT"
      },
      "source": [
        "In diesem Kapitel wird ein Neuronales Netz aus drei Schichten aufgebaut. \r\n",
        "\r\n",
        "Zunächst wird die Anzahl der Klassen festgelegt. \r\n",
        "\r\n",
        "Aufgabe 3\r\n",
        "\r\n",
        "3a.) Wie viele Klassen sind vorhanden und wie kommt diese Zahl zustande?\r\n",
        "\r\n",
        "3b.) Welche Schicht des Neuronalen Netzes wird durch die Anzahl der Klassen festgelegt?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1x6G5GjMvFs"
      },
      "source": [
        "# Wie viele Klassen haben wir? \r\n",
        "num_classes = ##"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWle-NDiYqvk"
      },
      "source": [
        "Die Anzahl der Neuronen in der verdeckten, zweiten Schicht (Hidden Layer) werden durch keinen Parameter vorgegeben. Sie werden zu 19 festgelegt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV_ksEONZB0P"
      },
      "source": [
        "neurons_second_layer = 19"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydmrICAKaHfV"
      },
      "source": [
        "Im nächsten Schitt wird das Neuronale Netz aufgebaut. \r\n",
        "\r\n",
        "Mit der Angabe Sequential() wird festgelegt, dass Schichten nacheinander über model.add() hinzugefügt werden. \r\n",
        "\r\n",
        "Zwei Arten von Schichten werden verwendet: Dense und Flatten. Dense bedeutet, dass eine eindimensinale Schicht vorliegt, deren Neuronen vollständig mit allen Neuronen der nachfolgenden Schicht verknüpft ist.\r\n",
        "Die Schicht Flatten erfüllt die gleiche Funktion und enthält noch eine weitere Funktion. \r\n",
        "\r\n",
        "Aufgabe 4: Welche Funktion könnte die Schicht \"Flatten\" erfüllen, und warum ist diese Funktion notwendig?\r\n",
        "\r\n",
        "Bei Hinzufügen einer Schicht werden die Anzahl der Neuronen durch die Variable units festgelegt. Ausnahme stellt die erste Schicht dar, in der die Anzahl der Neuronen über input_shape festgelegt werden. \r\n",
        "\r\n",
        "Bei allen Schichten (außer der ersten Schicht) wird eine Funktion angegeben, nach der die Neuronen aktiviert werden (Aktivierungsfunktion). Informationen zu möglichen Aktivierungsfunktionen befinden sich bspw. hier:\r\n",
        "\r\n",
        " https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoTU8Zav3L3b"
      },
      "source": [
        "# Initialisierung des Neuronalen Netzes\n",
        "model = Sequential()\n",
        "\n",
        "# Aufbau des Neuronalen Netzes\n",
        "## Schicht 1:\n",
        "model.add(Flatten(input_shape=(image_side_lentgh,image_side_lentgh, 1)))\n",
        "\n",
        "## Schicht 2:\n",
        "model.add(Dense(units=neurons_second_layer, activation='relu'))\n",
        "\n",
        "## Schicht :\n",
        "model.add(Dense(units=num_classes, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBTGGJT-c1he"
      },
      "source": [
        "In der nachfolgenden Tabelle wird eine Übersicht und ein Schaubild des neuronalen Netzes ausgegeben. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPdcsHqy3M83",
        "outputId": "3a7b1ddc-26ac-4a6e-c41c-8a56f616fa55"
      },
      "source": [
        "## Ausgabe der Netzarchitektur  \n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 19)                14915     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 60        \n",
            "=================================================================\n",
            "Total params: 14,975\n",
            "Trainable params: 14,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FslXUIvogQbj"
      },
      "source": [
        "In der nächsten Zelle wird das Neuronale Netz kompiliert. \r\n",
        "\r\n",
        "Mit dem Optimizer werden Einstellungen für die Anpassung der Gewichte festgelegt. Die Lernrate (lr) bestimmt beispielsweise die Schrittgröße bei der Gewichtsanpassung. \r\n",
        "\r\n",
        "Die Loss-Funktion, auch Kostenfunktion genannt, beschreibt im Groben die Abweichung der Gewichte der Output-Layer von den idealen Gewichten der Output-Layer.   \r\n",
        "\r\n",
        "Es gibt verschiedene Möglichkeiten, des Loss zu berechnen. Weitere Informationen zu Loss-Funktionen finden sich hier: \r\n",
        "\r\n",
        "https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class\r\n",
        "\r\n",
        "Mit der \"Accuracy\" wird das Verhältnis der richtig vorhergesagten Bildern zu allen vorhergesagten Bildern beschrieben. Dieses Verhältnis liegt immer zwischen 0 und 1. 0 bedeutet, dass kein einziges Bild korrekt vorhergesagt wurde, 1 bedeutet, dass alle Bilder korrekt vorhergesagt wurden.\r\n",
        "\r\n",
        "Aufgabe 2e: In diesem Fall wird das Neuronale Netz auf drei Klassen trainiert. Welche Accuracy ist bei einem vollständig untrainierten Netz zu erwarten?\r\n",
        "\r\n",
        "Zusätzlich wird ein checkpoint angelegt, d.h. ein Speicherort für die besten Gewichtungen. Die besten Gewichtungen werden mithilfe des Validierungsdatensets ermittelt. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSU2iBejA8l3"
      },
      "source": [
        "# Kompilieren des Neuronalen Netzes\n",
        "\n",
        "my_optimizer = Adam(lr = 0.001) \n",
        "model.compile(optimizer = my_optimizer,\n",
        "                   loss = 'categorical_crossentropy',\n",
        "                   metrics = 'accuracy')   \n",
        "\n",
        "## Vorgabe zum Speichern des Netzes\n",
        "checkpoint_path = \"Checkpoint_NeuronalesNetz.ckpt\"\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    verbose = 1,\n",
        "    mode='max',\n",
        "    save_best_only=True)               "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Oa8j35k2cG"
      },
      "source": [
        "# 4. Training des Neuronalen Netzes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5ixjY2yjMqg"
      },
      "source": [
        "Das Neuronale Netz wird trainiert. Die Trainingsbilder und Validierungsbilder werden angegeben, sowie die Methode (callbacks), nach der die besten Gewichtungen gespeichert werden. \r\n",
        "\r\n",
        "Eine Epoche beschreibt den Ablauf, in dem jedes Bild des Datensets ein mal das Neuronale Netz durchlaufen hat. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLMlh3dvXwAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5708d62d-16b8-491b-fd58-5cfce65f5980"
      },
      "source": [
        "# Training des Neuronalen Netzes\n",
        "history = model.fit(train_images,\n",
        "                    epochs = 100,\n",
        "                    validation_data=validation_images,\n",
        "                    callbacks = model_checkpoint_callback\n",
        "                    )                    "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.1477 - accuracy: 0.3466 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.35084, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 1542s 39s/step - loss: 1.1477 - accuracy: 0.3466 - val_loss: 1.1585 - val_accuracy: 0.3508\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.3489\n",
            "Epoch 00002: val_accuracy did not improve from 0.35084\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 1.1695 - accuracy: 0.3489 - val_loss: 1.1622 - val_accuracy: 0.3079\n",
            "Epoch 3/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 1.0938 - accuracy: 0.4093\n",
            "Epoch 00003: val_accuracy improved from 0.35084 to 0.36277, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 1.0936 - accuracy: 0.4100 - val_loss: 1.1468 - val_accuracy: 0.3628\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0685 - accuracy: 0.4465\n",
            "Epoch 00004: val_accuracy improved from 0.36277 to 0.36516, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 1.0685 - accuracy: 0.4465 - val_loss: 1.1026 - val_accuracy: 0.3652\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0663 - accuracy: 0.4187\n",
            "Epoch 00005: val_accuracy improved from 0.36516 to 0.37709, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 1.0663 - accuracy: 0.4187 - val_loss: 1.0998 - val_accuracy: 0.3771\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0615 - accuracy: 0.4465\n",
            "Epoch 00006: val_accuracy improved from 0.37709 to 0.48210, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 1.0615 - accuracy: 0.4465 - val_loss: 1.0582 - val_accuracy: 0.4821\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0266 - accuracy: 0.4639\n",
            "Epoch 00007: val_accuracy did not improve from 0.48210\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 1.0266 - accuracy: 0.4639 - val_loss: 1.0396 - val_accuracy: 0.4558\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0409 - accuracy: 0.4766\n",
            "Epoch 00008: val_accuracy did not improve from 0.48210\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 1.0409 - accuracy: 0.4766 - val_loss: 1.0367 - val_accuracy: 0.4797\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.5083\n",
            "Epoch 00009: val_accuracy did not improve from 0.48210\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 1.0028 - accuracy: 0.5083 - val_loss: 1.0456 - val_accuracy: 0.4582\n",
            "Epoch 10/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9956 - accuracy: 0.4955\n",
            "Epoch 00010: val_accuracy improved from 0.48210 to 0.49642, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.9963 - accuracy: 0.4956 - val_loss: 1.0234 - val_accuracy: 0.4964\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9736 - accuracy: 0.5472\n",
            "Epoch 00011: val_accuracy did not improve from 0.49642\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.9736 - accuracy: 0.5472 - val_loss: 1.0328 - val_accuracy: 0.4535\n",
            "Epoch 12/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9860 - accuracy: 0.5126\n",
            "Epoch 00012: val_accuracy did not improve from 0.49642\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.9844 - accuracy: 0.5123 - val_loss: 1.0489 - val_accuracy: 0.4153\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9954 - accuracy: 0.5178\n",
            "Epoch 00013: val_accuracy did not improve from 0.49642\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.9954 - accuracy: 0.5178 - val_loss: 1.0744 - val_accuracy: 0.4296\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9536 - accuracy: 0.5670\n",
            "Epoch 00014: val_accuracy improved from 0.49642 to 0.51074, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.9536 - accuracy: 0.5670 - val_loss: 0.9968 - val_accuracy: 0.5107\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9429 - accuracy: 0.5599\n",
            "Epoch 00015: val_accuracy improved from 0.51074 to 0.52983, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.9429 - accuracy: 0.5599 - val_loss: 0.9976 - val_accuracy: 0.5298\n",
            "Epoch 16/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.5921\n",
            "Epoch 00016: val_accuracy did not improve from 0.52983\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.9177 - accuracy: 0.5924 - val_loss: 1.0352 - val_accuracy: 0.4439\n",
            "Epoch 17/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9415 - accuracy: 0.5663\n",
            "Epoch 00017: val_accuracy did not improve from 0.52983\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.9424 - accuracy: 0.5638 - val_loss: 1.0164 - val_accuracy: 0.5203\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9408 - accuracy: 0.5393\n",
            "Epoch 00018: val_accuracy did not improve from 0.52983\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.9408 - accuracy: 0.5393 - val_loss: 1.0085 - val_accuracy: 0.4821\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9421 - accuracy: 0.5305\n",
            "Epoch 00019: val_accuracy did not improve from 0.52983\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.9421 - accuracy: 0.5305 - val_loss: 1.0237 - val_accuracy: 0.4320\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9128 - accuracy: 0.5813\n",
            "Epoch 00020: val_accuracy did not improve from 0.52983\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.9128 - accuracy: 0.5813 - val_loss: 1.0058 - val_accuracy: 0.5155\n",
            "Epoch 21/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.9253 - accuracy: 0.5622\n",
            "Epoch 00021: val_accuracy improved from 0.52983 to 0.54177, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.9228 - accuracy: 0.5630 - val_loss: 0.9679 - val_accuracy: 0.5418\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8816 - accuracy: 0.5987\n",
            "Epoch 00022: val_accuracy did not improve from 0.54177\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8816 - accuracy: 0.5987 - val_loss: 0.9672 - val_accuracy: 0.5298\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.6003\n",
            "Epoch 00023: val_accuracy improved from 0.54177 to 0.55131, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8916 - accuracy: 0.6003 - val_loss: 0.9642 - val_accuracy: 0.5513\n",
            "Epoch 24/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8970 - accuracy: 0.5948\n",
            "Epoch 00024: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.8983 - accuracy: 0.5916 - val_loss: 0.9595 - val_accuracy: 0.5418\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8956 - accuracy: 0.6003\n",
            "Epoch 00025: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8956 - accuracy: 0.6003 - val_loss: 1.0153 - val_accuracy: 0.4439\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6233\n",
            "Epoch 00026: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8670 - accuracy: 0.6233 - val_loss: 0.9944 - val_accuracy: 0.5203\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8644 - accuracy: 0.6257\n",
            "Epoch 00027: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8644 - accuracy: 0.6257 - val_loss: 0.9618 - val_accuracy: 0.5465\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8641 - accuracy: 0.6130\n",
            "Epoch 00028: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8641 - accuracy: 0.6130 - val_loss: 0.9739 - val_accuracy: 0.5418\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8825 - accuracy: 0.5868\n",
            "Epoch 00029: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8825 - accuracy: 0.5868 - val_loss: 1.0192 - val_accuracy: 0.4654\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8716 - accuracy: 0.5987\n",
            "Epoch 00030: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8716 - accuracy: 0.5987 - val_loss: 0.9808 - val_accuracy: 0.4988\n",
            "Epoch 31/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8883 - accuracy: 0.6119\n",
            "Epoch 00031: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8914 - accuracy: 0.6082 - val_loss: 0.9602 - val_accuracy: 0.5107\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8207 - accuracy: 0.6534\n",
            "Epoch 00032: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8207 - accuracy: 0.6534 - val_loss: 1.0032 - val_accuracy: 0.5370\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8720 - accuracy: 0.6035\n",
            "Epoch 00033: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.8720 - accuracy: 0.6035 - val_loss: 1.1719 - val_accuracy: 0.4272\n",
            "Epoch 34/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8980 - accuracy: 0.5940\n",
            "Epoch 00034: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8942 - accuracy: 0.5971 - val_loss: 0.9492 - val_accuracy: 0.5370\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8225 - accuracy: 0.6392\n",
            "Epoch 00035: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.8225 - accuracy: 0.6392 - val_loss: 1.0334 - val_accuracy: 0.4893\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8486 - accuracy: 0.6416\n",
            "Epoch 00036: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.8486 - accuracy: 0.6416 - val_loss: 0.9439 - val_accuracy: 0.5465\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8668 - accuracy: 0.6090\n",
            "Epoch 00037: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8668 - accuracy: 0.6090 - val_loss: 0.9900 - val_accuracy: 0.4869\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.6511\n",
            "Epoch 00038: val_accuracy did not improve from 0.55131\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.8187 - accuracy: 0.6511 - val_loss: 0.9729 - val_accuracy: 0.5274\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8227 - accuracy: 0.6265\n",
            "Epoch 00039: val_accuracy improved from 0.55131 to 0.55370, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8227 - accuracy: 0.6265 - val_loss: 0.9644 - val_accuracy: 0.5537\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.5868\n",
            "Epoch 00040: val_accuracy did not improve from 0.55370\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8787 - accuracy: 0.5868 - val_loss: 1.0692 - val_accuracy: 0.4869\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7967 - accuracy: 0.6614\n",
            "Epoch 00041: val_accuracy did not improve from 0.55370\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.7967 - accuracy: 0.6614 - val_loss: 0.9474 - val_accuracy: 0.5418\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8046 - accuracy: 0.6590\n",
            "Epoch 00042: val_accuracy improved from 0.55370 to 0.58711, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.8046 - accuracy: 0.6590 - val_loss: 0.9368 - val_accuracy: 0.5871\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8032 - accuracy: 0.6479\n",
            "Epoch 00043: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.8032 - accuracy: 0.6479 - val_loss: 0.9332 - val_accuracy: 0.5823\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.6455\n",
            "Epoch 00044: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7944 - accuracy: 0.6455 - val_loss: 0.9556 - val_accuracy: 0.5656\n",
            "Epoch 45/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7974 - accuracy: 0.6477\n",
            "Epoch 00045: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8009 - accuracy: 0.6471 - val_loss: 1.0219 - val_accuracy: 0.5107\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8360 - accuracy: 0.6138\n",
            "Epoch 00046: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.8360 - accuracy: 0.6138 - val_loss: 0.9328 - val_accuracy: 0.5680\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7806 - accuracy: 0.6693\n",
            "Epoch 00047: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7806 - accuracy: 0.6693 - val_loss: 0.9769 - val_accuracy: 0.5012\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8229 - accuracy: 0.6170\n",
            "Epoch 00048: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8229 - accuracy: 0.6170 - val_loss: 0.9696 - val_accuracy: 0.5346\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7860 - accuracy: 0.6614\n",
            "Epoch 00049: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7860 - accuracy: 0.6614 - val_loss: 1.0424 - val_accuracy: 0.5251\n",
            "Epoch 50/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7679 - accuracy: 0.6697\n",
            "Epoch 00050: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7693 - accuracy: 0.6693 - val_loss: 0.9389 - val_accuracy: 0.5680\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.6495\n",
            "Epoch 00051: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7872 - accuracy: 0.6495 - val_loss: 0.9890 - val_accuracy: 0.5346\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7717 - accuracy: 0.6725\n",
            "Epoch 00052: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7717 - accuracy: 0.6725 - val_loss: 0.9797 - val_accuracy: 0.5418\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7633 - accuracy: 0.6638\n",
            "Epoch 00053: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7633 - accuracy: 0.6638 - val_loss: 0.9630 - val_accuracy: 0.5704\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7753 - accuracy: 0.6622\n",
            "Epoch 00054: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7753 - accuracy: 0.6622 - val_loss: 0.9563 - val_accuracy: 0.5680\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7741 - accuracy: 0.6701\n",
            "Epoch 00055: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7741 - accuracy: 0.6701 - val_loss: 1.0173 - val_accuracy: 0.5489\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8386 - accuracy: 0.6305\n",
            "Epoch 00056: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.8386 - accuracy: 0.6305 - val_loss: 0.9198 - val_accuracy: 0.5800\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7710 - accuracy: 0.6749\n",
            "Epoch 00057: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7710 - accuracy: 0.6749 - val_loss: 0.9783 - val_accuracy: 0.5418\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7683 - accuracy: 0.6566\n",
            "Epoch 00058: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.7683 - accuracy: 0.6566 - val_loss: 1.0384 - val_accuracy: 0.5227\n",
            "Epoch 59/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7889 - accuracy: 0.6509\n",
            "Epoch 00059: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.7926 - accuracy: 0.6487 - val_loss: 1.0775 - val_accuracy: 0.4893\n",
            "Epoch 60/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.8344 - accuracy: 0.6103\n",
            "Epoch 00060: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.8348 - accuracy: 0.6098 - val_loss: 0.9370 - val_accuracy: 0.5561\n",
            "Epoch 61/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7554 - accuracy: 0.6688\n",
            "Epoch 00061: val_accuracy did not improve from 0.58711\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7564 - accuracy: 0.6685 - val_loss: 0.9677 - val_accuracy: 0.5227\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7539 - accuracy: 0.6685\n",
            "Epoch 00062: val_accuracy improved from 0.58711 to 0.58950, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7539 - accuracy: 0.6685 - val_loss: 0.9217 - val_accuracy: 0.5895\n",
            "Epoch 63/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7354 - accuracy: 0.6884\n",
            "Epoch 00063: val_accuracy did not improve from 0.58950\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.7379 - accuracy: 0.6891 - val_loss: 1.0233 - val_accuracy: 0.5227\n",
            "Epoch 64/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7607 - accuracy: 0.6648\n",
            "Epoch 00064: val_accuracy did not improve from 0.58950\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7603 - accuracy: 0.6677 - val_loss: 0.9190 - val_accuracy: 0.5752\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7517 - accuracy: 0.6558\n",
            "Epoch 00065: val_accuracy did not improve from 0.58950\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7517 - accuracy: 0.6558 - val_loss: 0.9350 - val_accuracy: 0.5632\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7562 - accuracy: 0.6598\n",
            "Epoch 00066: val_accuracy did not improve from 0.58950\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7562 - accuracy: 0.6598 - val_loss: 0.9595 - val_accuracy: 0.5561\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.6883\n",
            "Epoch 00067: val_accuracy improved from 0.58950 to 0.59427, saving model to Checkpoint_NeuronalesNetz.ckpt\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7304 - accuracy: 0.6883 - val_loss: 0.9295 - val_accuracy: 0.5943\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.6875\n",
            "Epoch 00068: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7375 - accuracy: 0.6875 - val_loss: 0.9314 - val_accuracy: 0.5943\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7708 - accuracy: 0.6534\n",
            "Epoch 00069: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.7708 - accuracy: 0.6534 - val_loss: 1.0914 - val_accuracy: 0.5012\n",
            "Epoch 70/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7361 - accuracy: 0.6762\n",
            "Epoch 00070: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 2s 59ms/step - loss: 0.7368 - accuracy: 0.6764 - val_loss: 0.9659 - val_accuracy: 0.5800\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.6963\n",
            "Epoch 00071: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7143 - accuracy: 0.6963 - val_loss: 1.0730 - val_accuracy: 0.4821\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.6844\n",
            "Epoch 00072: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7458 - accuracy: 0.6844 - val_loss: 0.9919 - val_accuracy: 0.5346\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7318 - accuracy: 0.6852\n",
            "Epoch 00073: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7318 - accuracy: 0.6852 - val_loss: 0.9504 - val_accuracy: 0.5823\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7210 - accuracy: 0.6868\n",
            "Epoch 00074: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.7210 - accuracy: 0.6868 - val_loss: 1.1268 - val_accuracy: 0.4845\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7577 - accuracy: 0.6566\n",
            "Epoch 00075: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7577 - accuracy: 0.6566 - val_loss: 0.9364 - val_accuracy: 0.5585\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7349 - accuracy: 0.6931\n",
            "Epoch 00076: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.7349 - accuracy: 0.6931 - val_loss: 0.9523 - val_accuracy: 0.5394\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7257 - accuracy: 0.6725\n",
            "Epoch 00077: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.7257 - accuracy: 0.6725 - val_loss: 0.9197 - val_accuracy: 0.5823\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.7050\n",
            "Epoch 00078: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.6913 - accuracy: 0.7050 - val_loss: 0.9609 - val_accuracy: 0.5632\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.6875\n",
            "Epoch 00079: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7260 - accuracy: 0.6875 - val_loss: 1.0869 - val_accuracy: 0.4988\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.6646\n",
            "Epoch 00080: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7308 - accuracy: 0.6646 - val_loss: 1.1555 - val_accuracy: 0.4916\n",
            "Epoch 81/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.7063\n",
            "Epoch 00081: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.6980 - accuracy: 0.7050 - val_loss: 0.9794 - val_accuracy: 0.5322\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.7050\n",
            "Epoch 00082: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7011 - accuracy: 0.7050 - val_loss: 0.9172 - val_accuracy: 0.5776\n",
            "Epoch 83/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7528 - accuracy: 0.6778\n",
            "Epoch 00083: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7493 - accuracy: 0.6812 - val_loss: 0.9199 - val_accuracy: 0.5776\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.7105\n",
            "Epoch 00084: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.6868 - accuracy: 0.7105 - val_loss: 0.9287 - val_accuracy: 0.5656\n",
            "Epoch 85/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7162 - accuracy: 0.6884\n",
            "Epoch 00085: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.7189 - accuracy: 0.6868 - val_loss: 0.9378 - val_accuracy: 0.5752\n",
            "Epoch 86/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7042 - accuracy: 0.6957\n",
            "Epoch 00086: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.7109 - accuracy: 0.6915 - val_loss: 0.9464 - val_accuracy: 0.5585\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7229 - accuracy: 0.6939\n",
            "Epoch 00087: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.7229 - accuracy: 0.6939 - val_loss: 0.9312 - val_accuracy: 0.5632\n",
            "Epoch 88/100\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.7003 - accuracy: 0.7046\n",
            "Epoch 00088: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7009 - accuracy: 0.7050 - val_loss: 0.9366 - val_accuracy: 0.5895\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6904 - accuracy: 0.7105\n",
            "Epoch 00089: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.6904 - accuracy: 0.7105 - val_loss: 0.9306 - val_accuracy: 0.5632\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.7098\n",
            "Epoch 00090: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.6798 - accuracy: 0.7098 - val_loss: 1.0710 - val_accuracy: 0.5370\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6610 - accuracy: 0.7232\n",
            "Epoch 00091: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.6610 - accuracy: 0.7232 - val_loss: 0.9384 - val_accuracy: 0.5823\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6644 - accuracy: 0.7153\n",
            "Epoch 00092: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.6644 - accuracy: 0.7153 - val_loss: 0.9868 - val_accuracy: 0.5632\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.7113\n",
            "Epoch 00093: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.6916 - accuracy: 0.7113 - val_loss: 0.9505 - val_accuracy: 0.5632\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.7137\n",
            "Epoch 00094: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.6739 - accuracy: 0.7137 - val_loss: 0.9593 - val_accuracy: 0.5823\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.6669\n",
            "Epoch 00095: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.7505 - accuracy: 0.6669 - val_loss: 1.0371 - val_accuracy: 0.5609\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.7272\n",
            "Epoch 00096: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.6547 - accuracy: 0.7272 - val_loss: 0.9533 - val_accuracy: 0.5632\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.7121\n",
            "Epoch 00097: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.6802 - accuracy: 0.7121 - val_loss: 0.9110 - val_accuracy: 0.5823\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6745 - accuracy: 0.7224\n",
            "Epoch 00098: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 0.6745 - accuracy: 0.7224 - val_loss: 0.9874 - val_accuracy: 0.5632\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.7177\n",
            "Epoch 00099: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 64ms/step - loss: 0.6672 - accuracy: 0.7177 - val_loss: 0.9827 - val_accuracy: 0.5752\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7343\n",
            "Epoch 00100: val_accuracy did not improve from 0.59427\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.6492 - accuracy: 0.7343 - val_loss: 0.9338 - val_accuracy: 0.5656\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW3gD0Y3unw-"
      },
      "source": [
        "# 5. Treffen von Vorhersagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq1CiJMvkX0j"
      },
      "source": [
        "Zunächst werden die besten Gewichtungen geladen. Die 30 Testbilder werden mit dem ImageDataGenerator genauso bearbeitet, wie die Trainingsbilder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS8mAVcrMcHd"
      },
      "source": [
        "# Laden der Gewichtungen des Neuronalen Netzes\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Vorhersage des Bildes\n",
        "image_index = 0\n",
        "number_of_images = 30\n",
        "test_generator = ImageDataGenerator(rescale = 1./ 255)\n",
        "\n",
        "test_images = data_generation.flow_from_directory( path_test_images,\n",
        "                                                    target_size = (image_side_lentgh,image_side_lentgh),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    color_mode = 'grayscale',\n",
        "                                                    shuffle= False\n",
        "                                                    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdhAWiVTlYln"
      },
      "source": [
        "Die Testbilder werden durch den Befehl predict vorhergesagt. Alle Bilder werden im Anschluss mit der dazugehörigen Vorhersage angezeigt. \r\n",
        "\r\n",
        "Aufgabe 6\r\n",
        "\r\n",
        "6a.) Bei welchen Formen funktioniert die Vorhersage gut, bei welchen Formen funktioniert die Vorhersage weniger gut? \r\n",
        "\r\n",
        "6b.) Was könnte der Grund dafür sein, dass manche Formen leichter vorhergesagt werden, als andere? Tipp: Betrachte dafür auch die Trainingsbilder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiayfWr4lIIv"
      },
      "source": [
        "all_predictions = model.predict(test_images)\r\n",
        "\r\n",
        "# Anzeige der vorhergesagten Bilder\r\n",
        "x,y = test_images.next()\r\n",
        "\r\n",
        "for i in range(image_index ,image_index+number_of_images):\r\n",
        "    one_pred = all_predictions[i]\r\n",
        "    print(one_pred)\r\n",
        "\r\n",
        "    predicition_name = np.argmax(one_pred)\r\n",
        "    if predicition_name == 0:\r\n",
        "        print(\"Kreis\") \r\n",
        "    if predicition_name == 1:\r\n",
        "        print(\"Viereck\")\r\n",
        "    if predicition_name == 2:\r\n",
        "        print(\"Dreieck\")\r\n",
        "\r\n",
        "    image = x[i]\r\n",
        "    print(image.shape)\r\n",
        "    plt.imshow(image.reshape(28,28), cmap = \"gray\")\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Xp5cZepKQQ"
      },
      "source": [
        "Zum Überprüfen der Qualität des Neuronalen Netzes werden die je Loss-Funktion und die Accuracy der Validierungsdaten der Trainings- und der Testbilder aufgezeichnet. Die Loss-Funktion sollte möglichst minimiert werden, die Accuracy sollte maximiert werden. \r\n",
        "\r\n",
        "Aufgabe 7: Diese Aufgabe ist etwas zeitaufwändiger, da das Modell zwei Mal trainiert werden muss. \r\n",
        "\r\n",
        "7a. Setze die Anzahl der Epochen durch die Variable \"epochs = \" bei der Funktion model.fit() einmal auf 10 und einmal auf 200 und lass das Neuronale Netz mit dieser Anzahl Epochen trainieren. Wenn du die Plots in der nachfolgenden Zelle erstellst: Wie verändert sich der Plot der Accuracy und der Loss-Funktion bei sehr vielen / wenigen Epochen? \r\n",
        "7b. (schwierig) Kannst du zu beiden Fällen die Begriffe Overfitting und Underfitting zuorden?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHN-eBL9BHr1"
      },
      "source": [
        "# Plotten der Genauigkeit (Accuracy)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train' ], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['val_accuracy'], label='Categorical Crossentropy (training data)')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.ylabel('categorical_crossentropy value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbiLC8_-1dT"
      },
      "source": [
        "# Plotten der Loss-Funktion\n",
        "plt.plot(history.history['loss'], label='Categorical Crossentropy (training data)')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('categorical_crossentropy value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['val_loss'], label='Categorical Crossentropy (training data)')\n",
        "plt.title('Val_Loss')\n",
        "plt.ylabel('categorical_crossentropy value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JidTa0BkIQOj"
      },
      "source": [
        "---\r\n",
        "# Lösungen zu den Aufgaben"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuGNkPQpIVXs"
      },
      "source": [
        "1a.) Öffne die Ordnerstruktur am linken Rand des Notebooks. In welchem Verzeichnis wurden die Bilder gespeichert? \r\n",
        "\r\n",
        "Die Bilder befinden sich unter drive/My\\ Drive/Formen/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbCRtvJ-I_9i"
      },
      "source": [
        "\r\n",
        "1b.) Nach welchem System wurden die Bilder sortiert? Weshalb ist diese Sortierung notwendig? \r\n",
        "\r\n",
        "Die Bilder sind nach Trainings- und Testbildern sortiert. Mit den Trainingsbildern wird das Netz trainiert, mit den Testbildern wird die Qualität des Netzes getestet. \r\n",
        "Zusätzlich sind die Bilder nach der abgebildeten Form sortiert. Alle Kreise, alle Dreiecke und alle Vierecke für das Training befinden sich in je einem Ordner. Dadurch wird gewährleistet, dass den Bildern die richtige Klasse zugeordnet wird"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEFFc0COWDIF"
      },
      "source": [
        "1c.) Um die Trainingsbilder und Testbildern in ein Datenset einzufügen, wird der Pfad dorthin ebnötigt. In der nächsten Zelle wird der Pfad für die Trainignsbilder mit der Variable path_train_images angegeben. Gib nach dem gleichen Schema den den Pfad für die Testbilder unter der Variable path_test_images an.\r\n",
        "\r\n",
        "path_test_images = './Formen/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHQAzjjtPE_E"
      },
      "source": [
        "2.) Warum müssen alle Bilder die gleiche Seitenlänge haben?\r\n",
        "\r\n",
        "Jedes Pixel entspricht einem Neuron in der Input Layer des Neuronalen Netzes. Wenn sich die Größen der Bilder unterscheiden, sind entweder zu viele oder zu wenige Neuronen in dieser Schicht worhanden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmRkxlF2YNLN"
      },
      "source": [
        "3a.) Wie viele Klassen sind vorhanden und wie kommt diese Zahl zustande?\r\n",
        "\r\n",
        "Drei Klassensind vorhanden , da drei verschiedene Formen (Dreiecke, Kreise und Vierecke) unterschieden werden. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdRQLT8jYOMt"
      },
      "source": [
        "3b.) Welche Schicht des Neuronalen Netzes wird durch die Anzahl der Klassen festgelegt?\r\n",
        "\r\n",
        "Durch die Anzahl der Klassen wird die Anzahl der Ausgabeneuronen (Neuronen in der Output Layer) festgelegt. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75y6VAjQcXpZ"
      },
      "source": [
        "4) Welche Funtkion könnte die Schicht \"Flatten\" erfüllen, und warum ist diese Funktion notwendig?\r\n",
        "\r\n",
        "Die Schicht Flatten erstellt aus einem zweidimensionalen Bild einen eindimensionalen Vektor. Dieser ist notwendig, um jedem Neuron der Input Layer einen Wert zuzuweisen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y7yzubMiWHL"
      },
      "source": [
        "5.) In diesem Fall wird das Neuronale Netz auf drei Klassen trainiert. Welche Accuracy ist bei einem vollständig untrainierten Netz zu erwarten?\r\n",
        "\r\n",
        "Ein untrainiertes Netz würde zufällig Vorhersagen treffen. Somit läge die erwartete Accuracy bei 1/3 (0.3333)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9M7--TlmdaZ"
      },
      "source": [
        "6a.) Bei welchen Formen funktioniert die Vorhersage gut, bei welchen Formen funktioniert die Vorhersage weniger gut? \r\n",
        "\r\n",
        "Bei Dreiecken und Vierecken funktioniert die Vorhersage deutlich besser als bei Kreisen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkIHDyCemftg"
      },
      "source": [
        "6b.) Was könnte der Grund dafür sein, dass manche Formen leichter vorhergesagt werden, als andere? Tipp: Betrachte dafür auch die Trainingsbilder.\r\n",
        "\r\n",
        "Dreiecke und Vierecke sind leichter voneinander abzugrenzen als Kreise, insbesondere wenn sie unsauber gezeichnet sind. Das ist auch im Datenset erkennbar, dass ein unsauber gezeichnetes Dreieck eher als Kreis, nicht aber als Viereck interpretierbar ist. Das gleiche gilt für Vierecke.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS1gR_LAqpzM"
      },
      "source": [
        "7a. Setze die Anzahl der Epochen durch die Variable \"epochs = \" bei der Funktion model.fit() einmal auf 10 und einmal auf 200 und lass das Neuronale Netz mit dieser Anzahl Epochen trainieren. Wenn du die Plots in der nachfolgenden Zelle erstellst: Wie verändert sich der Plot der Accuracy und der Loss-Funktion bei sehr vielen / wenigen Epochen? \r\n",
        "\r\n",
        "Bei wenigen Epochen hat das Neuronale Netz noch nicht ausreichend trainiert. Der Loss ist noch vergleichsweise hoch, die Accuracy vergleichsweise niedrig. \r\n",
        "\r\n",
        "Bei vielen Epochen kann es sein, dass der Validierungsloss erneut ansteigt und die Validierungs-Accuracy sinkt. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWplVTLHqqzw"
      },
      "source": [
        "7b. (schwierig) Kannst du zu beiden Fällen die Begriffe Overfitting und Underfitting zuorden?\r\n",
        "\r\n",
        "Underfitting bedeutet, dass das Neuronale Netz (noch) nicht genügend Muster aus dem Training herausfinden konnte. Dies kann durch ein zu kurzes Training resultieren.\r\n",
        "\r\n",
        "Overfitting bedeutet, dass das Neuronale Netz die Daten zu gut kennt und sie \"auswendig gelernt\" hat. Als Konsequenz kann das Neuronale Netz neue Bilder schlechter erkennen und somit verschlechtern sich die Validierungswerte. Dieser Effekt tritt bei einem zu langem Training auf.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDVGXQrC-zVV"
      },
      "source": [
        "Quelle: https://medium.com/tebs-lab/how-to-classify-mnist-digits-with-different-neural-network-architectures-39c75a0f03e3\n"
      ]
    }
  ]
}